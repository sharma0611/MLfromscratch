{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Helper-Classes\" data-toc-modified-id=\"Helper-Classes-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Helper Classes</a></span></li><li><span><a href=\"#Question-1\" data-toc-modified-id=\"Question-1-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Question 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importing-Data\" data-toc-modified-id=\"Importing-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Importing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Constants\" data-toc-modified-id=\"Constants-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Constants</a></span></li><li><span><a href=\"#Test-Data\" data-toc-modified-id=\"Test-Data-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Test Data</a></span></li><li><span><a href=\"#Training-/-Validation-Data\" data-toc-modified-id=\"Training-/-Validation-Data-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Training / Validation Data</a></span></li></ul></li><li><span><a href=\"#Mixture-of-Gaussians\" data-toc-modified-id=\"Mixture-of-Gaussians-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Mixture of Gaussians</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Definition\" data-toc-modified-id=\"Model-Definition-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Model Definition</a></span></li><li><span><a href=\"#Test-&amp;-Train-Accuracy\" data-toc-modified-id=\"Test-&amp;-Train-Accuracy-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Test &amp; Train Accuracy</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Parameters</a></span></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Definition\" data-toc-modified-id=\"Model-Definition-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Model Definition</a></span></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Cross Validation</a></span></li><li><span><a href=\"#Finding-the-Optimal-Lambda\" data-toc-modified-id=\"Finding-the-Optimal-Lambda-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Finding the Optimal Lambda</a></span></li><li><span><a href=\"#Test-&amp;-Train-Accuracy-with-Optimal-Lambda\" data-toc-modified-id=\"Test-&amp;-Train-Accuracy-with-Optimal-Lambda-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Test &amp; Train Accuracy with Optimal Lambda</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-3.3.5\"><span class=\"toc-item-num\">3.3.5&nbsp;&nbsp;</span>Parameters</a></span></li></ul></li><li><span><a href=\"#Discussion\" data-toc-modified-id=\"Discussion-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Discussion</a></span></li></ul></li><li><span><a href=\"#Question-2b\" data-toc-modified-id=\"Question-2b-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Question 2b</a></span><ul class=\"toc-item\"><li><span><a href=\"#Experiment\" data-toc-modified-id=\"Experiment-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Experiment</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from abc import ABC, abstractmethod \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFetcher:\n",
    "    \"\"\"\n",
    "    DataFetcher: Grabs all csv data as pandas dataframes.\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, X_name, y_name):\n",
    "        self.directory = directory\n",
    "        self.X_name = X_name\n",
    "        self.y_name = y_name\n",
    "        \n",
    "    def _get_training_X_path(self, subset_num):\n",
    "        # 0 <= subset_num <= 9\n",
    "        return './%s/train%s%d.csv' % (self.directory, self.X_name, (subset_num + 1))\n",
    "\n",
    "    def _get_training_y_path(self, subset_num):\n",
    "        # 0 <= subset_num <= 9\n",
    "        return './%s/train%s%d.csv' % (self.directory, self.y_name, (subset_num + 1))\n",
    "\n",
    "    def get_all_training_X_y(self):\n",
    "        training_X_dfs = []\n",
    "        training_y_dfs = []\n",
    "        for i in range(NUM_SUBSETS):\n",
    "            X_path = self._get_training_X_path(i)\n",
    "            y_path = self._get_training_y_path(i)\n",
    "            X_df = pd.read_csv(X_path, header=None)\n",
    "            y_df =  pd.read_csv(y_path, header=None)\n",
    "            training_X_dfs.append(X_df)\n",
    "            training_y_dfs.append(y_df)\n",
    "        \n",
    "        return training_X_dfs, training_y_dfs\n",
    "    \n",
    "    def get_test_X_y(self):\n",
    "        test_X_path = './%s/test%s.csv' % (self.directory, self.X_name)\n",
    "        test_y_path = './%s/test%s.csv' % (self.directory, self.y_name)\n",
    "        test_X_df = pd.read_csv(test_X_path, header=None)\n",
    "        test_y_df = pd.read_csv(test_y_path, header=None)\n",
    "        return test_X_df, test_y_df\n",
    "    \n",
    "class CrossValidationData:\n",
    "    \"\"\"\n",
    "    CrossValidationData: Splits list of training dataframes \n",
    "        into validation & training dataframes.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_dfs, y_dfs):\n",
    "        assert(len(X_dfs) == len(y_dfs))\n",
    "        self.X = X_dfs\n",
    "        self.y = y_dfs\n",
    "        self.num_subsets = len(X_dfs)\n",
    "        \n",
    "    def _split_training_validation(self, dfs, subset_num):\n",
    "        \n",
    "        validation_df = dfs[subset_num]\n",
    "        \n",
    "        training_dfs = dfs[:subset_num] + dfs[subset_num+1:]\n",
    "        training_df = pd.concat(training_dfs, ignore_index=True)\n",
    "      \n",
    "        return [training_df, validation_df]     \n",
    "        \n",
    "    def _get_training_validation_X(self, subset_num):\n",
    "        assert(subset_num < self.num_subsets)\n",
    "        \n",
    "        [training_X, validation_X] = self._split_training_validation(self.X, subset_num)\n",
    "        \n",
    "        return [training_X, validation_X]\n",
    "    \n",
    "    def _get_training_validation_y(self, subset_num):\n",
    "        assert(subset_num < self.num_subsets)\n",
    "        \n",
    "        [training_y, validation_y] = self._split_training_validation(self.y, subset_num)\n",
    "        \n",
    "        return [training_y, validation_y]\n",
    "    \n",
    "    def get_training_validation_X_y(self, subset_num):\n",
    "        [training_X, validation_X] = self._get_training_validation_X(subset_num)\n",
    "        [training_y, validation_y] = self._get_training_validation_y(subset_num)\n",
    "        return [training_X, training_y, validation_X, validation_y]\n",
    "\n",
    "    def get_all_X_y(self):\n",
    "        training_X = pd.concat(self.X, ignore_index=True)\n",
    "        training_y = pd.concat(self.y, ignore_index=True)\n",
    "        return [training_X, training_y]\n",
    "    \n",
    "def get_accuracy(true_labels, predicted_labels):\n",
    "    assert(len(true_labels) == len(predicted_labels))\n",
    "    return sum(1 for y, y_hat in zip(true_labels, predicted_labels) if y == y_hat ) / len(true_labels)\n",
    "\n",
    "class Model(ABC):\n",
    "    \"\"\"\n",
    "    Model -> Abstract base class for the models we will implement, namely \n",
    "            KNN and RidgeRegression.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_X, train_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "        \n",
    "    def predict_df(self, X_df):\n",
    "        predictions = X_df.apply(lambda row: self.predict(row), raw=True, axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "## Importing Data\n",
    "\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = 'knn-dataset'\n",
    "X_NAME = 'Data'\n",
    "Y_NAME = 'Labels'\n",
    "NUM_SUBSETS = 10\n",
    "POSITIVE_LABEL = 6\n",
    "NEGATIVE_LABEL = 5\n",
    "LAMBDAS = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  54  55  56  57  58  59  60  \\\n",
       "0   0   0   0   1  13  10   0   0   0   8  ...  16   0   0   0   4   0  14   \n",
       "1   0   0   0   0   0   7   0   0   0   0  ...  16   0   0   0   0   0   2   \n",
       "2  16  11   5  16  15  16  16  16  16  16  ...  14  16  16  16  16  16  16   \n",
       "3   0   0   7  16   2   2   0   0   0   1  ...  11   0   0   0   0   9   9   \n",
       "4   0   0   0   7   0   0   0   0   0   0  ...   0   0   0   0   0  13  14   \n",
       "\n",
       "   61  62  63  \n",
       "0   0  15   0  \n",
       "1  11  12   0  \n",
       "2  16  16   0  \n",
       "3   0   0   0  \n",
       "4  12   0   0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = DataFetcher(DIR_NAME, X_NAME, Y_NAME)\n",
    "test_X, test_y = DF.get_test_X_y()\n",
    "\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  6\n",
       "1  6\n",
       "2  5\n",
       "3  6\n",
       "4  6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X shape: (900, 64)\n"
     ]
    }
   ],
   "source": [
    "training_X_dfs, training_y_dfs = DF.get_all_training_X_y()\n",
    "\n",
    "CVData = CrossValidationData(training_X_dfs, training_y_dfs)\n",
    "\n",
    "print(\"Training X shape: \" + str(CVData.get_training_validation_X_y(0)[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training y shape: (900, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training y shape: \" + str(CVData.get_training_validation_X_y(0)[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation X shape: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation X shape: \" + str(CVData.get_training_validation_X_y(0)[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation y shape: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation y shape: \" + str(CVData.get_training_validation_X_y(0)[3].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture of Gaussians\n",
    "\n",
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixture(Model):\n",
    "    \n",
    "    def __init__(self, train_X, train_y, positive_label, negative_label):\n",
    "        super().__init__(train_X, train_y)\n",
    "        self.positive_label = positive_label\n",
    "        self.negative_label = negative_label\n",
    "        \n",
    "        # MLE Estimates for parameters\n",
    "        y_list = train_y.values.flatten().tolist()\n",
    "        pi = sum([1 if y == positive_label else 0 for y in y_list]) / len(y_list)\n",
    "        \n",
    "        # for mew 1, mew 2, split train X into positive negative groups and take average vector\n",
    "        positive_indices = [ind for ind, y in enumerate(y_list) if y == positive_label]\n",
    "        negative_indices = [ind for ind, y in enumerate(y_list) if y != positive_label]\n",
    "        \n",
    "        n1 = len(positive_indices)\n",
    "        n2 = len(negative_indices)\n",
    "        \n",
    "        N = n1 + n2\n",
    "        \n",
    "        positive_X_df = train_X.iloc[positive_indices]\n",
    "        negative_X_df = train_X.iloc[negative_indices]\n",
    "        \n",
    "        mu_1 = positive_X_df.mean()\n",
    "        mu_2 = negative_X_df.mean()\n",
    "        \n",
    "        positive_X = positive_X_df.to_numpy()\n",
    "        negative_X = negative_X_df.to_numpy()\n",
    "\n",
    "        positive_X_dists = positive_X_df.to_numpy() - mu_1.to_numpy()\n",
    "        negative_X_dists = negative_X_df.to_numpy() - mu_2.to_numpy()\n",
    "\n",
    "        s1 = positive_X_dists.T.dot(positive_X_dists) / n1\n",
    "        s2 = negative_X_dists.T.dot(negative_X_dists) / n2\n",
    "\n",
    "        cov = (n1/N) * s1 + (n2/N) * s2\n",
    "        \n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "        \n",
    "        w = cov_inv.dot(mu_1 - mu_2)\n",
    "        w_0 = -(1/2) * mu_1.T.dot(cov_inv).dot(mu_1) + (1/2) * mu_2.T.dot(cov_inv).dot(mu_2) + np.log(pi/ (1-pi))\n",
    "\n",
    "        self.pi = pi\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.mu_1 = mu_1\n",
    "        self.mu_2 = mu_2\n",
    "        self.cov = cov\n",
    "        self.w = w\n",
    "        self.w_0 = w_0\n",
    "        \n",
    "    def predict_prob(self, x):\n",
    "        logit_odds = self.w.dot(x) + self.w_0\n",
    "        prob = 1 / (1 + np.exp(-logit_odds))        \n",
    "        return prob\n",
    "    \n",
    "    def predict(self, x):\n",
    "        prob = self.predict_prob(x)\n",
    "        if prob > 0.5:\n",
    "            return self.positive_label\n",
    "        else:\n",
    "            return self.negative_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test & Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.884000\n",
      "Test Accuracy: 0.890909\n",
      "Training Time: 0.006109952926635742\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = CVData.get_all_X_y()\n",
    "\n",
    "# Create hypothesis\n",
    "t1 = time.time()\n",
    "model = GaussianMixture(train_X, train_y, POSITIVE_LABEL, NEGATIVE_LABEL)\n",
    "t2 = time.time()\n",
    "\n",
    "# Train Accuracy \n",
    "predicted_train_y = model.predict_df(train_X)\n",
    "train_accuracy = get_accuracy(train_y.values.flatten(), predicted_train_y.values.flatten())\n",
    "\n",
    "# Test Accuracy\n",
    "predicted_test_y = model.predict_df(test_X)\n",
    "test_accuracy = get_accuracy(test_y.values.flatten(), predicted_test_y.values.flatten())\n",
    "\n",
    "print(\"Train Accuracy: %f\" % train_accuracy)\n",
    "print(\"Test Accuracy: %f\" % test_accuracy)\n",
    "print(\"Training Time: \" + str(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi = 0.500000\n",
      "mu_1 = [ 5.158  4.954  5.654  9.55   8.618  5.482  5.478  4.896  4.782  4.75\n",
      "  8.194 10.272  7.03   5.272  4.864  4.736  4.864  5.058  9.814  8.438\n",
      "  4.92   5.068  4.762  4.882  4.686  5.76  10.572  8.02   6.306  5.47\n",
      "  5.154  4.664  4.988  6.278 10.67   9.814  9.532  8.804  5.84   4.588\n",
      "  4.832  5.732 10.402  9.132  7.756  9.324  8.338  4.732  4.704  5.334\n",
      "  9.224  9.968  7.304  9.668  8.934  4.968  4.932  5.002  5.84   9.202\n",
      " 10.99   9.72   6.41   5.186]\n",
      "mu_2 = [ 4.846  4.902  8.28   9.858 10.68   9.342  6.198  4.602  4.978  5.998\n",
      " 10.498  9.662  8.448  7.66   5.322  4.412  4.438  6.36  10.02   6.84\n",
      "  5.6    4.764  4.436  4.366  4.758  6.392 10.126  9.514  7.924  6.302\n",
      "  4.532  4.64   4.812  5.274  7.596  7.948  8.518  7.668  5.634  4.226\n",
      "  4.612  4.718  4.924  5.762  7.362  8.612  5.764  4.408  4.29   5.038\n",
      "  7.032  7.762  8.782  7.908  5.516  4.548  4.456  4.758  8.606 10.226\n",
      "  8.702  6.198  5.002  4.944]\n",
      "diag(cov) = [40.06966  39.82214  43.393942 42.766668 40.430838 42.431356 43.962156\n",
      " 35.76039  37.639996 39.744748 41.88718  42.250886 43.980198 40.399208\n",
      " 39.59391  37.22228  35.94983  40.826518 42.785502 46.726278 39.7868\n",
      " 38.79184  35.49763  36.49206  36.55942  40.446368 40.62147  46.540702\n",
      " 45.725294 43.487948 37.28763  36.988752 37.872256 42.13782  41.990942\n",
      " 44.39835  45.407326 45.28368  42.051222 32.90459  37.272616 39.713326\n",
      " 40.32731  44.527966 46.29971  43.68424  43.72803  35.242856 35.657142\n",
      " 40.4655   44.1844   44.524166 46.08703  44.612656 43.811694 38.729336\n",
      " 37.56372  37.560716 45.240582 42.59006  42.565548 43.998198 42.671948\n",
      " 40.080134]\n"
     ]
    }
   ],
   "source": [
    "print(\"pi = %f\" % model.pi)\n",
    "print(\"mu_1 = \" + str(model.mu_1.to_numpy()))\n",
    "print(\"mu_2 = \" + str(model.mu_2.to_numpy()))\n",
    "print(\"diag(cov) = \" + str(np.diag(model.cov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(Model):\n",
    "    def __init__(self, train_X, train_y, positive_label, negative_label, lmbda=0,  max_iters=10, threshold=0.01, train_intercept=True):\n",
    "        super().__init__(train_X, train_y)\n",
    "        self.positive_label = positive_label\n",
    "        self.negative_label = negative_label\n",
    "        self.lmbda = lmbda\n",
    "        self.max_iters = max_iters\n",
    "        self.threshold = threshold\n",
    "        self.train_intercept = train_intercept\n",
    "        \n",
    "        X = train_X.to_numpy()\n",
    "        y = train_y.to_numpy()\n",
    "        \n",
    "        # y's as 1 & 0's\n",
    "        y = [1 if y_i == positive_label else 0 for y_i in y]\n",
    "\n",
    "        # Add column of ones\n",
    "        if train_intercept:\n",
    "            X = np.insert(X, 0, np.ones(len(X)), axis=1)\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.w = np.zeros(X.shape[1])\n",
    "        \n",
    "        self._train(self.X, self.w, self.y)\n",
    "    \n",
    "    def _sigmoid(self, odds):\n",
    "        prob = 1 / (1 + np.exp(-odds))\n",
    "        return prob\n",
    "    \n",
    "    def _gradient(self, X, w, y):\n",
    "        weighted_values = X.dot(w)\n",
    "\n",
    "        probabilities = np.apply_along_axis(self._sigmoid, 0, weighted_values)\n",
    "\n",
    "        return X.T.dot(probabilities - y) + self.lmbda * w\n",
    "    \n",
    "    def _inverse_proba(self, prob):\n",
    "        return 1 - prob\n",
    "    \n",
    "    def _R(self, X, w):\n",
    "        weighted_values = X.dot(w)\n",
    "        \n",
    "        probabilities = np.apply_along_axis(self._sigmoid, 0, weighted_values)\n",
    "        inv_probabilities = np.apply_along_axis(self._inverse_proba, 0, probabilities)\n",
    "\n",
    "        return np.diag(np.multiply(probabilities, inv_probabilities))\n",
    "    \n",
    "    def _hessian(self, X, w):\n",
    "        R = self._R(X, w)\n",
    "        H = X.T.dot(R).dot(X)\n",
    "        return H + self.lmbda * np.identity(len(H))\n",
    "    \n",
    "    def _train(self, X, w, y):\n",
    "        iters = 0\n",
    "        while(True):\n",
    "            if iters >= self.max_iters:\n",
    "                break\n",
    "            \n",
    "            gradient = self._gradient(X, w, y)\n",
    "            hessian = self._hessian(X, w)\n",
    "            hessian_inv = np.linalg.inv(hessian)\n",
    "            \n",
    "            w_new = w - hessian_inv.dot(gradient)\n",
    "            \n",
    "            dist = norm(w_new - w)\n",
    "            \n",
    "            w = w_new\n",
    "\n",
    "            if dist < self.threshold:\n",
    "                break\n",
    "\n",
    "            iters += 1\n",
    "\n",
    "        self.w = w\n",
    "        \n",
    "    def predict_prob(self, x):\n",
    "        if self.train_intercept:\n",
    "            x = np.insert(x, 0, 1)\n",
    "        odds = self.w.dot(x) \n",
    "        return self._sigmoid(odds)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        prob = self.predict_prob(x)\n",
    "        if prob > 0.5:\n",
    "            return self.positive_label\n",
    "        else:\n",
    "            return self.negative_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logreg_CV():\n",
    "\n",
    "    average_accuracies = []\n",
    "    for lmbda in tqdm_notebook(LAMBDAS):\n",
    "        # Perform CV\n",
    "        accuracies = []\n",
    "        for j in range(NUM_SUBSETS):\n",
    "            train_X, train_y, validation_X, validation_y = CVData.get_training_validation_X_y(j)\n",
    "            \n",
    "            # Create hypothesis\n",
    "            model = LogisticRegression(train_X, train_y, POSITIVE_LABEL, NEGATIVE_LABEL, lmbda)\n",
    "            predicted_validation_y = model.predict_df(validation_X)\n",
    "\n",
    "            # Get accuracy\n",
    "            accuracy = get_accuracy(validation_y.values.flatten(), predicted_validation_y.values.flatten())\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        average_accuracies.append(avg_accuracy)\n",
    "\n",
    "    return average_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Optimal Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1448d539c1b4993af53c2e82ffd6513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal lambda is 9000.000000 with an average accuracy of 0.887000\n"
     ]
    }
   ],
   "source": [
    "cv_accuracies = perform_logreg_CV()\n",
    "optimal_lambda = LAMBDAS[np.argsort(cv_accuracies)[-1]]\n",
    "print(\"The optimal lambda is %f with an average accuracy of %f\" % (optimal_lambda, max(cv_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LAMBDAS, cv_accuracies)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Cross Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test & Train Accuracy with Optimal Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.893000\n",
      "Test Accuracy: 0.900000\n",
      "Training Time (s): 0.020524978637695312\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = CVData.get_all_X_y()\n",
    "\n",
    "# Create hypothesis\n",
    "t1 = time.time()\n",
    "model = LogisticRegression(train_X, train_y, POSITIVE_LABEL, NEGATIVE_LABEL, optimal_lambda)\n",
    "t2 = time.time()\n",
    "\n",
    "# Train Accuracy \n",
    "predicted_train_y = model.predict_df(train_X)\n",
    "train_accuracy = get_accuracy(train_y.values.flatten(), predicted_train_y.values.flatten())\n",
    "\n",
    "# Test Accuracy\n",
    "predicted_test_y = model.predict_df(test_X)\n",
    "test_accuracy = get_accuracy(test_y.values.flatten(), predicted_test_y.values.flatten())\n",
    "\n",
    "print(\"Train Accuracy: %f\" % train_accuracy)\n",
    "print(\"Test Accuracy: %f\" % test_accuracy)\n",
    "print(\"Training Time (s): \" + str(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_0 = -0.0007261238590916078\n",
      "w = [ 0.00228753 -0.00218262 -0.02499607 -0.00677616 -0.02156872 -0.04263319\n",
      " -0.00888297 -0.00031574 -0.00933602 -0.01046375 -0.02821003  0.00133734\n",
      " -0.01630065 -0.03102114 -0.00421849  0.00478879  0.00057688 -0.01515247\n",
      " -0.00717007  0.0115508  -0.0079005   0.00312802  0.00437815  0.00472446\n",
      " -0.0051537  -0.00910076  0.00018878 -0.01708027 -0.01901705 -0.0054421\n",
      "  0.00678872 -0.00122225 -0.0034087   0.00794875  0.02455587  0.01430453\n",
      "  0.00313639  0.01047607  0.00224912  0.00508369  0.00246666  0.00583231\n",
      "  0.05520182  0.0299953  -0.00031288 -0.00124383  0.01620232  0.00140322\n",
      " -0.00097509  0.00852071  0.0171887   0.01673538 -0.01840872  0.01219147\n",
      "  0.02774324  0.00128359  0.00540749  0.00557576 -0.03186668 -0.01486028\n",
      "  0.01550594  0.02840391  0.00908849  0.00305927]\n"
     ]
    }
   ],
   "source": [
    "print(\"w_0 = \" + str(model.w[0]))\n",
    "print(\"w = \" + str(model.w[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "1. **Compare the number of parameters for Gaussian Mixtures and Logistic Regression.**\n",
    "\n",
    "The parameters of the Gaussian Mixture model are Ï€, $Î¼_1$, $Î¼_2$, Î£. \n",
    "\n",
    "For an input space in $R^n$, $Î¼_1$ and $Î¼_2$ are both n-dimensional, Ï€ is scalar, and Î£ is an n x n matrix. Î£ has a symmetrical upper and lower triangle. Thus, all the parameters are:\n",
    "\n",
    "- Ï€\n",
    "- $Î¼_{1i}$ for $0 < i < n$\n",
    "- $Î¼_{2i}$ for $0 < i < n$\n",
    "- $Î£_{ij}$ for $0 < i < n, 0 < j < n, i <= j$\n",
    "\n",
    "They each correspond to:\n",
    "\n",
    "- 1 parameter\n",
    "- n parameters\n",
    "- n parameters\n",
    "- 1 + 2 + ... + n = n * (n + 1) / 2 parameters\n",
    "\n",
    "The total number of parameters in the Gaussian Mixture model is $\\frac{n^2}{2} + \\frac{5n}{2} + 1$\n",
    "\n",
    "For our data in the 64-dimensional digits dataset, this equals 2209 parameters.\n",
    "\n",
    "The parameters of the Logistic Regression model is w and $w_0$ where w is n dimensional and $w_0$ is scalar.\n",
    "\n",
    "Thus, the total number of parameters in the Logistic Regression model is n + 1. \n",
    "\n",
    "For our data above, this equals 65 parameters.\n",
    "\n",
    "The Gaussian Mixture model is heavily parameterized in comparison to the Logistic Regression model. This shows that the Gaussian Mixture model has less degress of freedom. This makes sense because the Logistic Regression model can represent any conditional distribution $P(x|C_i)$ in the exponential family, where the Gaussian Mixture model only represents one of these possibilities (the Gaussian conditional). \n",
    "\n",
    "2. **Compare the amount of computation for both models.**\n",
    "\n",
    "There are two areas where computation is involved: the complexity involved to learn the parameters, and the complexity involved to predict a value. We will consider both in our analsyis as the computational complexity of learning, and the computational complexity of prediction.\n",
    "\n",
    "Let's consider the complexity of learning as the asymptotic computational complexity of calculating the parameters as a function of the dimensionality of the data, n, and the number of training samples, m.\n",
    "\n",
    "For the Gaussian Mixture model, we calculate Ï€ by finding the proportion of points that belongs to a class. This is an $O(m)$ operation. We calculate $Î¼_1$ by taking the average across each dimension for all the points in a class. This is an $O(mn)$ operation. WLOG, this also applies to to $Î¼_2$. To calculate the covariance matrix we subtract each mean from $X_{y=c_{1}}$ and $X_{y=c_{2}}$ respectively and taking $X^TX$ for each and combining them. Subtracting the mean can be done in $O(m)$ and calculating $X^TX$ can be done by taking a dot product of two m dimensional vectors for n^2 positions in the resulting matrix, an $O(mn^2)$ operation. So, the covariance can be calculated in $O(m) + O(mn^2) = O(mn^2)$.\n",
    "\n",
    "Finally, combining the above complexities, $O(m) + O(mn) + O(mn^2) = O(mn^2)$ is the computational complexity of learning for the Gaussian Mixture model.\n",
    "\n",
    "The computational complexity of prediction for the Gaussian Mixture model is simply to take the weights learned and dot them with the input vector and then apply a sigmoid transformation. This is done in $O(n)$.\n",
    "\n",
    "Now, let's consider the complexity of learning for the logistic regression model. Let's assume that 10 iterations is sufficient for convergence. \n",
    "\n",
    "In each iteration, we calculate the hessian, we calculate the gradient, we find the inverse of the hessian, dot the inverse by the gradient, and subtract the result from w to find the new w.\n",
    "\n",
    "To calculate the hessian, we calculate $X^TRX + Î»I$ where R is a diagonal matrix with m non-zero elements that represent each training sample's sigmoid probability ($Ïƒ_i$) multiplied by its inverse probability ($1-Ïƒ_i$). R is calculated in $O(mn)$ since each of the m elements is calculated from the dot product of two n dimensional vectors. To calculate $X^TR$, each column is multiplied by a diagonal element of R. Thus, the computational complexity is $O(mn)$. Then to calculate $X^TRX$ from the previous step, it will take $O(mn^2)$. We know this from our results involving calculating the covariance matrix in the Gaussian Mixture model case. Finally, to add the regularization term is an $O(n)$ operation. In summary, calculating the hessian is an $O(mn) + O(mn^2) + O(n)= O(mn^2) $ operation.\n",
    "\n",
    "To calculate the gradient, we take all the difference between sigmoid probabilities for each training sample and the y label and dot that with X and add the regularization term. This takes $O(mn) + O(mn) + O(n) = O(mn)$ time.\n",
    "\n",
    "To calculate the inverse of the n x n hessian matrix, it takes $O(n^3)$. I'm using the result here for the time complexity of naive Gaussian elimination, documented here: http://mathforum.org/library/drmath/view/51908.html. I don't think the goal of this assignment is to discuss the time complexity of Gaussian elimination, so I will use this result freely.\n",
    "\n",
    "The time complexity of learning for the Logistic Regression model is then $O(mn^2) + O(mn) + O(n^3) = O(mn^2) + O(n^3)$. If $m > n$, which should really be true if you want meaningful results, then the time complexity is simply $O(mn^2)$.\n",
    "\n",
    "The time complexity of prediction for the Logistic Regression model is the same as the Gaussian result at $O(n)$.\n",
    "\n",
    "In summary, the time complexity of learning for Gaussian Mixture models and Logistic Regression is $O(mn^2)$ and the time complexity of prediction for both is $O(n)$.\n",
    "\n",
    "In wall clock time, the results for training both models are as follows:\n",
    "\n",
    "Gaussian Mixture: 0.0048 seconds\n",
    "\n",
    "Logistic Regression: 0.0176 seconds\n",
    "\n",
    "These values may vary from the ones above, since I just took the ones I got on this specific run of the notebook.\n",
    "\n",
    "The wall clock times make sense because the logistic regression does up to 10 more iterations, with each iteration in $O(mn^2)$. These finite iterations make no difference to the asymptotic complexity, but in wall clock time the difference is clear.\n",
    "\n",
    "3. **Compare the results for both models.**\n",
    "\n",
    "The Gaussian Mixture model gave us:\n",
    "\n",
    "Train Accuracy: 0.884000\n",
    "Test Accuracy: 0.890909\n",
    "\n",
    "The Logistic Regression model gave us:\n",
    "\n",
    "Train Accuracy: 0.894000\n",
    "Test Accuracy: 0.900000\n",
    "\n",
    "The logistic regression model fits the data slightly better.\n",
    "\n",
    "4. **Compare the expressivity of KNN and linear seperators. Discuss under what circumstances each type of seperator is expected to perform best.**\n",
    "\n",
    "K-Nearest Neighbours is able to express complex non-linear hypotheses as a function of the training data. In KNN, the input space is partitioned with various degrees of smoothing as we increase k. KNN's decision boundary can take on any form since it is non-parametric.\n",
    "\n",
    "KNN is expected to do well if the training data is very representative of the true distribution. Although, if there are many training points, this may result in decreased speed when forming predictions since many more comparisons need to be made. KNN evaluates all features as equally important (has no concept of feature importance), so if this is not true, KNN may not be well suited to the problem. KNN is also not suited to the problem if there are linearities between features, since KNN does not capture these.\n",
    "\n",
    "The Gaussian Mixture model is able to express hypotheses with a linear decision boundary between two classes of data that are conditionally normally distributed around $Î¼_1$ and $Î¼_2$ with the same covariance matrix of Î£.\n",
    "\n",
    "The Gaussian Mixture model is expcted to perform best if the conditional normality conditions are satisfied and both classes have the same covariance matrix. The model can work best when the two classes can be linearly seperated. The model is effective at capturing linearity between features. The model is also robust to irrelevant features since it can assign those features a weight close to zero if they are less important.\n",
    "\n",
    "The Logistic Regression model is able to express hypotheses with a linear decision boundary between two classes of data that are conditionally distributed according to some unknown exponential distribution. This model is effective for data that is linearly seperable and follows some exponential distribution. The model is effective at capturing linearities between features and is also robust to irrelevant features. Logistic Regression should be used when there is a strong belief that the features are dependent on the class, and the features of both classes are different from one another. \n",
    "\n",
    "5. **What can explain the results of KNN in comparison to Gaussian Mixtures and Logistic Regression.**\n",
    "\n",
    "KNN gave us a test accuracy of 0.727 where both Gaussian Mixture and Logistic Regression gave us close to 0.9 test accuracy. The linear seperators vastly outperformed KNN. \n",
    "\n",
    "The reason for this can be understood by taking a look what the data represents. Each feature represents the number of dark pixels found in a 4x4 patch. Each feature is spatially correlated to one another. For the digits 5 and 6, we would expect that some features in tandem could define a 5, where the prescence of other features in tandem could represent a 6. We expect the features to have linearities between each other. KNN is unable to capture these linearities, where the linear seperators are able to create a linear decision boundary defined between features. \n",
    "\n",
    "Furthermore, we would expect some features to be more important than other features. For example, if we superimpose a 5 on top of a 6, we can tell that most of the shape may be identical except for the bottom left of the 6 and the the 5. This may lead these specific feature to be more important than the rest. Generally, we would also expect the features along the perimeter of the image to also be less important.\n",
    "\n",
    "We can verify this by taking a look at the weights we learned. In the logistic regression model, the 8th weight represents the weight for the feature in the top right corner of the image. This value is -9.17977578e-06. This is the lowest magnitude value from all the features. The linear seperators are able to learn this feature is less important where the KNN model gives this feature the same importance.\n",
    "\n",
    "These factors contribute to the linear seperators outperforming KNN on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2b\n",
    "\n",
    "Consider a set of data D that is linearly seperable. \n",
    "\n",
    "In a logistic regression, we minimize the negative log likelihood to form a linear decision boundary. For the data D, the weights, $w$, that would minimize the negative log likelihood form a decision boundary, $w^Tx = 0$, that linearly seperates the data D perfectly, and whose weights tend to infinity. \n",
    "\n",
    "The reason for this is as follows: Imagine that we have weights w for a linear boundary that accomplishes perfect classification on D. We can minimize the negative log likelihood further by multiplying all the weights by some c. This will keep the boundary in the same place but increase the magnitude of $w^Tx$ for any points. Thus, the sigmoid function will tend to a step function or threshold function with each iteration. With each iteration, we expect the magnitude of weights to increase.\n",
    "\n",
    "Using this knowledge, we can conduct an experiment to see if the training data is linearly seperable. We should train a logistic regression classifier on the training data and check to see if the mode has 100% on the train set. If it is true, we can confirm that the data is linearly seperable. A training accuracy of 100% is enough to prove the data is linearly seperable since the linear decision boundary classifies each point perfectly. For interest, I would like to also take a look at the weights themselves as well as I increase the number of iterations.\n",
    "\n",
    "A natural question is what should our regularization parameter be? \n",
    "\n",
    "For a linearly seperable dataset, regularization should not matter since the magnitude of the weights only affects how the sigmoid function looks and should not alter the linear boundary from its optimum. \n",
    "\n",
    "However, we want to avoid a hessian matrix with no inverse so we will use a small value for lambda in the logistic regression.\n",
    "\n",
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81f28d8aba64fa881f1a7a327af9eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = CVData.get_all_X_y()\n",
    "\n",
    "NUM_ITERS = [10, 20, 30, 40]\n",
    "\n",
    "weight_norms = []\n",
    "train_accuracies = []\n",
    "\n",
    "for num in tqdm_notebook(NUM_ITERS):\n",
    "    \n",
    "    # Create hypothesis\n",
    "    model = LogisticRegression(train_X, train_y, POSITIVE_LABEL, NEGATIVE_LABEL, 10, max_iters=num, threshold=0.001)\n",
    "\n",
    "    # Train Accuracy \n",
    "    predicted_train_y = model.predict_df(train_X)\n",
    "    train_accuracy = get_accuracy(train_y.values.flatten(), predicted_train_y.values.flatten())\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    weight_norms.append(norm(model.w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAbUklEQVR4nO3dfbhcZX3u8e8NiEERoyTaSpAAwqHxjeoWbesRBEW0CgW1QkHkaKvWQrVH2mKPVsWjVevr1UPbg6i8lBZTbDVtaaliUE4rmo0ICAhEVAigBAERrELgd/5Yz8Zxs5JMSCaz9873c11zZdbLrPVbe8Hcs55n1jOpKiRJmm6rcRcgSZqZDAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuA0IyS5M6Bx31J/mtg+siN2O6FSY5azzq/m+Tqtq/vJfnnJNsNse2Dkqwcso73JqkkTx22dmlcDAjNKFW1/dQDuA54ycC8M0e13yQvAN4KvLTt+0nAP2zifWwFHAXcChy9Kbc9zL7b/qWh+R+MZpUkWyd5W5Jrk9yS5Mwk89uyhyc5K8mtSW5P8pUkj0ryQeAZwCnt6uCDPZt+BnBBVV0GUFW3VNUnquq/2ra3S/KRJNe3q4u/SPLQJDsC/wjsNnCls+Nayn8e8EjgfwJHJtlm2rG9Ick3k/woyWVJntzmL07y2Xa8t0zV365GThl4/V5J1gxMX5jkxCRfAX4MPC7J6wb2sTLJq6fV8PIkl7bl1yQ5IMkrk/zHtPX+JMmn1n22NNsZEJptjgcOBJ4NLALuAT7clv02sA2wE7AAOBa4u6reDKwAfrtdiby5Z7sXAgcn+dMkv5Jk22nLP9T292TgvwF7AidU1Q+AQ4FrB650frCW2l9FFyZLgYcBL5hakOSVwB8DRwA7AC8DbkvyEOBfgSuBxwM7A59e/5/pfkfRXa08AvgecBPwwraP1wMnJXliq+E5wMnAG+mC7ADgerorqScn2XVgu68ETt+AOjQLGRCabV5P98Z8Y1X9BHgn8IokoQuLhcDuVbWmqlZU1V3DbLSqPg8cDjwTOBe4Jcn7WtPMNsBrgDdW1e1V9UPgvW39oSTZgS5I/rZdlfwjP9/M9NvAe6rq4upcVVWr6IJwB+BPqurHVfVfVfWfw+4XOKVt6572N1lWVd9u+/g88MW2D9ox/nVVLa+q+6rquqq6uv0NP00XNiSZAHZsfyfNYdusfxVpZmghsDNwTpLBUSa3onvD+jjwC8DZSban+4T7tqq6d5jtV9UyYFlrq38+8PfAFcBy4CHA5V0JXTnAmr7trMXLgR8Bn2/TZwKfTTK/qm5vx/WtntftDHy7qu7bgH0Nun5wIsnBdH0tT6D7uz0MuGBgXxfQ7zTgr4F30QXF31XVhhy/ZiGvIDRrVDf08A3A/lU1f+Axr/UZ/LSq/rSq9gKeQ/emPPUpf+hhi9un53OBL9F1Vt9EFwa7D+zzkVU11dcwzLZfBcwHViX5HnAGMA94RVt+PbB7z+uuBxavpYP5Lro3+Cm/0Hc4U0+SPJwu9N4FPKaq5gNfoAu7ddUA3ZXGvCTPomsGO2Mt62kOMSA02/w18N4kOwMkeUySl7Tnz0uypL2Z3kH3pj71yfv7wG5r22iSl7UO2vnp/Crwa8CFVXUP8Ango0kWtOU7J3n+wLYf065a+ra9G10zzoHA3u3xVOAj/KyZ6RTghCRPbdvfM8ki4P/RXXm8K8nDWmf5r7bXfB14bpKdkjyKrg9jXbajuxK6GbivXU3sN7D8FOB1SZ7TmtZ2TrIn3B/OZ9D1UfygqibXsy/NAQaEZpv30zXTfCHJj4D/BJ7Wlu0EfJbuDfUbwDnA1DdtPgwcneS2JO/v2e5twBvomnnuoAuEd1bVVIfwm4AbgUngh8C/0TXTAFwCLAO+27499ehp2z4a+HJVfbGqvjf1AD4KPDPJHlV1Bl1H+Nmt/rOB+S2cXkQXKKvovvp7aNvuvwD/TNcMdiHwmXX94arqFrpO/n8CfgD8RvsbTS2/gK6P5y/bMZ5H1zE/5XS6TnqvHrYQ8QeDJA0jySPorpb2qqrrxl2PRs8rCEnDOg4433DYcvgtJknr1TrWfwwcPO5atPnYxCRJ6mUTkySp10ibmJIcRPdNja3p7uh877Tlu9B9W2Qh3QBmR7W7R6eW70D3DY3PVNWx69rXggULavHixZv2ACRpjrvoootuqaqFfctGFhBJtgZOorsjdRWwIsmyqrpiYLUPAKdX1WlJ9gf+jG6MlynvortZab0WL17M5KRfzZakDZHku2tbNsompn2AlVV1bVXdDZwFHDJtnSV0d3JCN5zB/cuTPB14LPDvI6xRkrQWowyInfj5cWBWtXmDLgEOa88PBR6RZMd2J+wH6W7qWaskr00ymWRy9erVm6hsSRKMv5P6eGDfJBcD+9KNs3Mv3R2t5wz2R/SpqpOraqKqJhYu7G1CkyQ9SKPspL6BbnTIKYvavPtV1Y20K4g2js1Lq+r2JL8C/PckbwC2B7ZNcmdVnTDCeiVJA0YZECuAPdqPjNxAN6rmbw2ukGQBcGsbyvgtdN9ooqqOHFjnGGDCcJCkzWtkTUxtrPhj6X5U5EpgaVVd3n4CcepuzP2Aq5JcTdch/e5R1SNJ2jBz5k7qiYmJ8muukrRhklxUVRN9y8bdSS1JmqEMCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1GukAZHkoCRXJVmZ5ISe5bskOS/JpUnOT7Kozd87yZeTXN6WvWKUdUqSHmhkAZFka+Ak4IXAEuCIJEumrfYB4PSqegpwIvBnbf6PgaOr6onAQcBHkswfVa2SpAca5RXEPsDKqrq2qu4GzgIOmbbOEuAL7fnyqeVVdXVVXdOe3wjcDCwcYa2SpGlGGRA7AdcPTK9q8wZdAhzWnh8KPCLJjoMrJNkH2Bb41vQdJHltkskkk6tXr95khUuSxt9JfTywb5KLgX2BG4B7pxYm+UXgDOB/VNV9019cVSdX1URVTSxc6AWGJG1K24xw2zcAOw9ML2rz7teajw4DSLI98NKqur1N7wD8C/C/qurCEdYpSeoxyiuIFcAeSXZNsi1wOLBscIUkC5JM1fAW4BNt/rbAP9J1YJ89wholSWsxsoCoqjXAscC5wJXA0qq6PMmJSQ5uq+0HXJXkauCxwLvb/N8EngMck+Tr7bH3qGqVJD1QqmrcNWwSExMTNTk5Oe4yJGlWSXJRVU30LRt3J7UkaYYyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUq+RBkSSg5JclWRlkhN6lu+S5LwklyY5P8migWWvSnJNe7xqlHVKkh5ovQGR5Lgkj9rQDSfZGjgJeCGwBDgiyZJpq30AOL2qngKcCPxZe+2jgbcDzwT2Ad7+YGqQJD14w1xBPBZYkWRpuyLIkNveB1hZVddW1d3AWcAh09ZZAnyhPV8+sPwFwOeq6taqug34HHDQkPuVJG0C6w2IqnorsAfwceAY4Jok70my+3peuhNw/cD0qjZv0CXAYe35ocAjkuw45GtJ8tokk0kmV69evb5DkSRtgKH6IKqqgO+1xxrgUcDZSd6/kfs/Htg3ycXAvsANwL3DvriqTq6qiaqaWLhw4UaWIkkatM36VkjyRuBo4BbgFOAPq+qeJFsB1wB/tJaX3gDsPDC9qM27X1XdSLuCSLI98NKquj3JDcB+0157/hDHI0naRNYbEMCjgcOq6ruDM6vqviQvXsfrVgB7JNmVLhgOB35rcIUkC4Bbq+o+4C3AJ9qic4H3DHRMH9iWS5I2k2GamP4VuHVqIskOSZ4JUFVXru1FVbUGOJbuzf5KYGlVXZ7kxCQHt9X2A65KcjVdZ/i722tvBd5FFzIrgBPbPEnSZpKue2EdK3T9A09r/RC0pqXJqnraZqhvaBMTEzU5OTnuMiRpVklyUVVN9C0b5goiNZAirTlomKYpSdIsNkxAXJvk95M8pD3eCFw76sIkSeM1TEC8HvhVuo7mVXR3N792lEVJksZvvU1FVXUz3TeQJElbkGHug5gHvAZ4IjBvan5VvXqEdUmSxmyYJqYzgF+gGx/pi3Q3rf1olEVJksZvmIB4QlW9Dbirqk4Dfp2uH0KSNIcNExD3tH9vT/Ik4JHAY0ZXkiRpJhjmfoaT25AXbwWWAdsDbxtpVZKksVtnQLS7pu9ov8nwJWC3zVKVJGns1tnE1O6aXttorZKkOWyYJqbPJzke+BRw19TMuTR43jv/6XKuuPGOcZchSQ/KksftwNtf8sRNvt1hAuIV7d/fG5hX2NwkSXPaMHdS77o5ChmnUSSvJM12w9xJfXTf/Ko6fdOXI0maKYZpYnrGwPN5wAHA1wADQpLmsGGamI4bnE4yHzhrZBVJkmaEYe6knu4uYM73S0jSlm6YPoh/ovvWEnSBsgRYOsqiJEnjN0wfxAcGnq8BvltVq0ZUjyRphhgmIK4DbqqqnwAk2S7J4qr6zkgrkySN1TB9EH8P3DcwfW+bJ0maw4YJiG2q6u6pifZ829GVJEmaCYYJiNVJDp6aSHIIcMvoSpIkzQTD9EG8Hjgzyf9p06uA3rurJUlzxzA3yn0LeFaS7dv0nSOvSpI0duttYkryniTzq+rOqrozyaOS/O/NUZwkaXyG6YN4YVXdPjXRfl3uRaMrSZI0EwwTEFsneejURJLtgIeuY31J0hwwTCf1mcB5ST4JBDgGOG2URUmSxm+YTur3JbkEeB7dmEznAruMujBJ0ngNO5rr9+nC4eXA/sCVI6tIkjQjrPUKIsmewBHtcQvwKSBV9dzNVJskaYzW1cT0TeAC4MVVtRIgyR9slqokSWO3riamw4CbgOVJPpbkALpOaknSFmCtAVFVn6mqw4G9gOXAm4DHJPmrJAdurgIlSeOx3k7qqrqrqv62ql4CLAIuBv54mI0nOSjJVUlWJjmhZ/njkyxPcnGSS5O8qM1/SJLTklyW5Mokb9nA45IkbaQN+k3qqrqtqk6uqgPWt26SrYGTgBfS/UzpEUmWTFvtrcDSqvpl4HDgL9v8lwMPraonA08HXpdk8YbUKknaOBsUEBtoH2BlVV3bfkPiLOCQaesUsEN7/kjgxoH5D0+yDbAdcDdwxwhrlSRNM8qA2Am4fmB6VZs36B3AUUlWAecAx7X5ZwN30XWSXwd8oKpunb6DJK9NMplkcvXq1Zu4fEnaso0yIIZxBHBqVS2iGwDwjCRb0V193As8DtgVeHOS3aa/uDV3TVTVxMKFCzdn3ZI0540yIG4Adh6YXtTmDXoNsBSgqr4MzAMWAL8F/FtV3VNVNwP/AUyMsFZJ0jSjDIgVwB5Jdk2yLV0n9LJp61wHHACQ5JfoAmJ1m79/m/9w4Fl0N+5JkjaTkQVEVa0BjqUb3O9Kum8rXZ7kxIHfuH4z8DttMMC/A46pqqL79tP2SS6nC5pPVtWlo6pVkvRA6d6PZ7+JiYmanJwcdxmSNKskuaiqepvwx91JLUmaoQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUy4CQJPUyICRJvQwISVIvA0KS1MuAkCT1MiAkSb0MCElSLwNCktTLgJAk9TIgJEm9DAhJUi8DQpLUa6QBkeSgJFclWZnkhJ7lj0+yPMnFSS5N8qKBZU9J8uUklye5LMm8UdYqSfp524xqw0m2Bk4Cng+sAlYkWVZVVwys9lZgaVX9VZIlwDnA4iTbAH8DvLKqLkmyI3DPqGqVJD3QKK8g9gFWVtW1VXU3cBZwyLR1CtihPX8kcGN7fiBwaVVdAlBVP6iqe0dYqyRpmlEGxE7A9QPTq9q8Qe8Ajkqyiu7q4bg2f0+gkpyb5GtJ/qhvB0lem2QyyeTq1as3bfWStIUbdyf1EcCpVbUIeBFwRpKt6Jq+ng0c2f49NMkB019cVSdX1URVTSxcuHBz1i1Jc94oA+IGYOeB6UVt3qDXAEsBqurLwDxgAd3Vxpeq6paq+jHd1cXTRlirJGmaUQbECmCPJLsm2RY4HFg2bZ3rgAMAkvwSXUCsBs4FnpzkYa3Del/gCiRJm83IvsVUVWuSHEv3Zr818ImqujzJicBkVS0D3gx8LMkf0HVYH1NVBdyW5EN0IVPAOVX1L6OqVZL0QOnej2e/iYmJmpycHHcZkjSrJLmoqib6lo27k1qSNEMZEJKkXgaEJKmXASFJ6mVASJJ6GRCSpF4GhCSplwEhSeplQEiSehkQkqReBoQkqZcBIUnqZUBIknoZEJKkXgaEJKmXASFJ6mVASJJ6GRCSpF4GhCSplwEhSeplQEiSehkQkqReBoQkqZcBIUnqZUBIknoZEJKkXgaEJKmXASFJ6mVASJJ6GRCSpF4GhCSplwEhSeqVqhp3DZtEktXAdzdiEwuAWzZROeM0V44DPJaZaq4cy1w5Dti4Y9mlqhb2LZgzAbGxkkxW1cS469hYc+U4wGOZqebKscyV44DRHYtNTJKkXgaEJKmXAfEzJ4+7gE1krhwHeCwz1Vw5lrlyHDCiY7EPQpLUyysISVIvA0KS1GuLC4gkn0hyc5JvDMx7dJLPJbmm/fuocdY4rLUcyzuS3JDk6+3xonHWOKwkOydZnuSKJJcneWObP6vOzTqOY9adlyTzknw1ySXtWN7Z5u+a5CtJVib5VJJtx13r+qzjWE5N8u2B87L3uGsdRpKtk1yc5J/b9EjOyRYXEMCpwEHT5p0AnFdVewDntenZ4FQeeCwAH66qvdvjnM1c04O1BnhzVS0BngX8XpIlzL5zs7bjgNl3Xn4K7F9VTwX2Bg5K8izgfXTH8gTgNuA1Y6xxWGs7FoA/HDgvXx9fiRvkjcCVA9MjOSdbXEBU1ZeAW6fNPgQ4rT0/DfiNzVrUg7SWY5mVquqmqvpae/4juv/4d2KWnZt1HMesU5072+RD2qOA/YGz2/wZf05gnccy6yRZBPw6cEqbDiM6J1tcQKzFY6vqpvb8e8Bjx1nMJnBskktbE9SMbpLpk2Qx8MvAV5jF52baccAsPC+tKePrwM3A54BvAbdX1Zq2yipmSQBOP5aqmjov727n5cNJHjrGEof1EeCPgPva9I6M6JwYENNU973fWfnJovkrYHe6y+ibgA+Ot5wNk2R74NPAm6rqjsFls+nc9BzHrDwvVXVvVe0NLAL2AfYac0kP2vRjSfIk4C10x/QM4NHAH4+xxPVK8mLg5qq6aHPsz4DofD/JLwK0f28ecz0PWlV9v/2PcB/wMbr/qWeFJA+he1M9s6r+oc2edeem7zhm83kBqKrbgeXArwDzk2zTFi0CbhhbYQ/CwLEc1JoEq6p+CnySmX9efg04OMl3gLPompY+yojOiQHRWQa8qj1/FfDZMdayUabeTJtDgW+sbd2ZpLWjfhy4sqo+NLBoVp2btR3HbDwvSRYmmd+ebwc8n65PZTnwsrbajD8nsNZj+ebAh4/QtdvP6PNSVW+pqkVVtRg4HPhCVR3JiM7JFncndZK/A/ajGx73+8Dbgc8AS4HH0w0Z/ptVNeM7f9dyLPvRNWMU8B3gdQNt+DNWkmcDFwCX8bO21T+ha7+fNedmHcdxBLPsvCR5Cl2H59Z0HyaXVtWJSXaj+/T6aOBi4Kj2CXzGWsexfAFYCAT4OvD6gc7sGS3JfsDxVfXiUZ2TLS4gJEnDsYlJktTLgJAk9TIgJEm9DAhJUi8DQpLUy4DQjJWkknxwYPr4JO/YRNs+NcnL1r/mRu/n5UmuTLJ82vzFU6PwJtl7U47ummR+kjcMTD8uydnreo3Ux4DQTPZT4LAkC8ZdyKCBO1aH8Rrgd6rquetYZ29ggwJiPTXMB+4PiKq6sapGHoaaewwIzWRr6H5r9w+mL5h+BZDkzvbvfkm+mOSzSa5N8t4kR7bfArgsye4Dm3lekskkV7cxbqYGdPvzJCvaAG6vG9juBUmWAVf01HNE2/43kryvzftT4NnAx5P8ed8BtnH7TwRe0X6P4BVJHt4G9PtqG/P/kLbuMUmWtZu7zkuyfZLzknyt7fuQttn3Aru37f35tKuVeUk+2da/OMlzB7b9D0n+Ld1vb7x/4O9xajuuy5I84Fxo7tqQT0LSOJwEXDr1hjWkpwK/RDcU+rXAKVW1T7of7zkOeFNbbzHd2Du7A8uTPAE4GvhhVT2jjez5H0n+va3/NOBJVfXtwZ0leRzdePxPpxuL/9+T/Ea7U3d/urtdJ/sKraq7W5BMVNWxbXvvoRtC4dVteIivJvn8QA1Pqapb21XEoVV1R7vKurAF2Amtzr3b9hYP7PL3ut3Wk5Ps1Wrdsy3bm2702Z8CVyX5C+AxwE5V9aS2rfnr+dtrDvEKQjNaGwn1dOD3N+BlK9ogbD+lG5566g3+MrpQmLK0qu6rqmvogmQv4EDg6HTDQn+FbijlPdr6X50eDs0zgPOranUbcvlM4DkbUO90BwIntBrOB+bRDTUC3TDVU0ONBHhPkkuBz9MN8by+4dCfDfwNQFV9k274kqmAOK+qflhVP6G7StqF7u+yW5K/SHIQcEfPNjVHeQWh2eAjwNfoRtucsob2ASfJVsDgTywOjkFz38D0ffz8f/PTx5kpujfd46rq3MEFbdybux5c+RsswEur6qppNTxzWg1H0o0j9PSquifdCJ/zNmK/g3+3e4Ftquq2JE8FXgC8HvhN4NUbsQ/NIl5BaMZrn5iX8vM/o/gduiYdgIPpfiFsQ708yVatX2I34CrgXOB30w3ZTZI9kzx8Pdv5KrBvkgVJtqYbmO+LG1DHj4BHDEyfCxyXJK2GX17L6x5J99sA97S+hF3Wsr1BF9AFC61p6fF0x92rNV1tVVWfBt5K18SlLYQBodnig3Sj1k75GN2b8iV0v1HwYD7dX0f35v6vdKN4/oTuZxyvAL7WOnb/L+u50m6jsp5AN+TyJcBFVbUhwy0vB5ZMdVID76ILvEuTXN6m+5wJTCS5jK7v5Jutnh/Q9Z18o6dz/C+BrdprPgUcs55RP3cCzm/NXX9D9wM72kI4mqskqZdXEJKkXgaEJKmXASFJ6mVASJJ6GRCSpF4GhCSplwEhSer1/wG7VcM8lJCfkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(NUM_ITERS, train_accuracies)\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Set Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(NUM_ITERS, weight_norms)\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Weight Norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs, it is clear that the training set is not linearly seperable.\n",
    "\n",
    "The accuracy does not reach 100% and the weights do not increase as we expect them to, instead the logistic regression converges to certain weights, and the train accuracy is below 0.9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csenv",
   "language": "python",
   "name": "csenv"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "069fd1fdbf8f40da9dcdf00b394b63bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9b33c89d49e043079d8ff040d21bb733",
       "style": "IPY_MODEL_75b3b1f021be431380839e1d5f80eb2c",
       "value": "100% 4/4 [00:00&lt;00:00, 14.86it/s]"
      }
     },
     "070630fcd29c441686452e7441f3f245": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cfa95ddf84a343de8049b4a0b6203f68",
        "IPY_MODEL_dd296ff948814848b9258f5413b6b184"
       ],
       "layout": "IPY_MODEL_885285f0593f41ab80f4dfea26a3d131"
      }
     },
     "07dae2e367814867b118b61caf8a4eaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b554088ad2349c18f664dbf1590cf54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1c866f88fbf44599a56a2011bde7710a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2297d64a145d4c8bb1a76c603c0baf0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3fa3f87a10784a8d9fb4c0dfb84a3fc5",
       "max": 4,
       "style": "IPY_MODEL_3164fc5f012f4ffca624a7dff35d8300",
       "value": 4
      }
     },
     "2525f9facb6b493b8fadcaa0e5885a72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2bb3c078e21a4d5fa4d0668a3c8efd27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2bf94a89d33b4b7ba271f4652255d682": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2f08ca71f47c45ac849a5e16c7ce8580": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a850f9015bc74fdca2c09cbb484dd4f0",
       "style": "IPY_MODEL_3ba7f1ce837945d3a14135a3ba9b1b70",
       "value": "100% 4/4 [00:00&lt;00:00, 14.25it/s]"
      }
     },
     "30a0dfa873754096bc2505b99247263f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3164fc5f012f4ffca624a7dff35d8300": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3314d5ef3cb04735b1ee8a8b74797b08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "35633c78954241a7ba33c98fe81b8cd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3628e3942e604f3d8926c3867213130d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37f8278cbbba4ee1bf212c9c1d19dcff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e431e7010dd241b7b3aa85b60b271386",
       "max": 4,
       "style": "IPY_MODEL_2525f9facb6b493b8fadcaa0e5885a72",
       "value": 4
      }
     },
     "3ba7f1ce837945d3a14135a3ba9b1b70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3fa3f87a10784a8d9fb4c0dfb84a3fc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "423b2bf6c9cc4cc285364a20432b09f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4409319d49ef4a3fa07c6663e0e9e5c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e52eb4cc1c0b417ebc266ee46eb9e1cb",
       "max": 4,
       "style": "IPY_MODEL_78a837765f704d66b38497606d56de0f",
       "value": 4
      }
     },
     "4b1b0163b5464c7cab543022be045420": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_30a0dfa873754096bc2505b99247263f",
       "style": "IPY_MODEL_d060b9d90c8749349f99c86691814e59",
       "value": "100% 4/4 [00:00&lt;00:00, 14.80it/s]"
      }
     },
     "4d604dccf9284b7ead93fc24bfa99ca8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5bcca0abd6cb467c95e4bbfbc8e94cd1",
       "max": 15,
       "style": "IPY_MODEL_5bb3b1722ef9416f8f21756d2ba51a5d",
       "value": 15
      }
     },
     "4e376083c13541a6a77742f0610880c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4f8841462e5b41bb80318c9f2ee877f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8b61ddc39abb45d7b508d8ae8da3a5ed",
       "style": "IPY_MODEL_65b17584bded4c619dabdedad44805a9",
       "value": "100% 15/15 [00:02&lt;00:00,  8.06it/s]"
      }
     },
     "5942d978f3f7476784a8cae98d7a1359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5bb3b1722ef9416f8f21756d2ba51a5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5bcca0abd6cb467c95e4bbfbc8e94cd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "61405267ed22498f98e85ba01ed166a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2bb3c078e21a4d5fa4d0668a3c8efd27",
       "max": 15,
       "style": "IPY_MODEL_e0163c429f45473384549678591e0fa9",
       "value": 15
      }
     },
     "65b17584bded4c619dabdedad44805a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "697aff7ce2b64f4095d4a6a998dd018c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fa3d2eb8611247949058e2e085827e9c",
       "style": "IPY_MODEL_1c866f88fbf44599a56a2011bde7710a",
       "value": "100% 15/15 [00:02&lt;00:00,  7.00it/s]"
      }
     },
     "6a5726147460447fa748275a970aeade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37f8278cbbba4ee1bf212c9c1d19dcff",
        "IPY_MODEL_4b1b0163b5464c7cab543022be045420"
       ],
       "layout": "IPY_MODEL_3314d5ef3cb04735b1ee8a8b74797b08"
      }
     },
     "716808e9a0f1466997908b10ec2e1e99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3628e3942e604f3d8926c3867213130d",
       "max": 4,
       "style": "IPY_MODEL_423b2bf6c9cc4cc285364a20432b09f0",
       "value": 4
      }
     },
     "75b3b1f021be431380839e1d5f80eb2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "78a837765f704d66b38497606d56de0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7c67b6df138b4f418fa32c9784d9f10c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b7e3b14c61b8444a84869d84c962ee2d",
       "style": "IPY_MODEL_35633c78954241a7ba33c98fe81b8cd1",
       "value": "100% 4/4 [00:00&lt;00:00, 16.61it/s]"
      }
     },
     "82bb05f129874e5b92b81d78aeb399b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8517e0f6324247b7bdcc1cf8ab7f2ee3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "885285f0593f41ab80f4dfea26a3d131": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8b61ddc39abb45d7b508d8ae8da3a5ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91793fc6d43e432498d1bb58a8a83acd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91ebf83757504c68be6451e4fea418d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_61405267ed22498f98e85ba01ed166a5",
        "IPY_MODEL_4f8841462e5b41bb80318c9f2ee877f3"
       ],
       "layout": "IPY_MODEL_82bb05f129874e5b92b81d78aeb399b1"
      }
     },
     "9370b3ef4f34454da60d8ee136a57448": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "93b9437ffb204d39bfca3d3f6be04a3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dc90d2523c76410ea760fd545412c75f",
        "IPY_MODEL_7c67b6df138b4f418fa32c9784d9f10c"
       ],
       "layout": "IPY_MODEL_f0ec0397132c4f708cc28fa900b7efbc"
      }
     },
     "9b33c89d49e043079d8ff040d21bb733": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9e8c9d17eb3e4348bf9b0cc5e72c0cba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9fbcd7f35d5a492784b62662f2daeb89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a1448d539c1b4993af53c2e82ffd6513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4d604dccf9284b7ead93fc24bfa99ca8",
        "IPY_MODEL_697aff7ce2b64f4095d4a6a998dd018c"
       ],
       "layout": "IPY_MODEL_2bf94a89d33b4b7ba271f4652255d682"
      }
     },
     "a34ba2ea2a6d4516adfac42d9e8d2458": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a4aa1e1644814056afb941dc635fefd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a5ff581541484859b8a55999b34699ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e8bd21d868a74162b12bd615434ca568",
        "IPY_MODEL_f1eb770ddeae4cf8a8fb6ea3ba758e35"
       ],
       "layout": "IPY_MODEL_07dae2e367814867b118b61caf8a4eaf"
      }
     },
     "a850f9015bc74fdca2c09cbb484dd4f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b7e3b14c61b8444a84869d84c962ee2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b81f28d8aba64fa881f1a7a327af9eec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_716808e9a0f1466997908b10ec2e1e99",
        "IPY_MODEL_c0ba5cc516cf47cab9526122fb19368c"
       ],
       "layout": "IPY_MODEL_f753bdbf644245338f43cdfa4a69e4bf"
      }
     },
     "bd3362181bf1444fa53c7d0eb93bb695": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0ba5cc516cf47cab9526122fb19368c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4e376083c13541a6a77742f0610880c6",
       "style": "IPY_MODEL_9e8c9d17eb3e4348bf9b0cc5e72c0cba",
       "value": "100% 4/4 [00:00&lt;00:00, 14.72it/s]"
      }
     },
     "cfa95ddf84a343de8049b4a0b6203f68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9fbcd7f35d5a492784b62662f2daeb89",
       "max": 4,
       "style": "IPY_MODEL_a4aa1e1644814056afb941dc635fefd9",
       "value": 4
      }
     },
     "d060b9d90c8749349f99c86691814e59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d6e8aa5647ed4d4aadd0a3c49f71bc11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8faa2ec73364fd981c0f640d546664b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2297d64a145d4c8bb1a76c603c0baf0a",
        "IPY_MODEL_2f08ca71f47c45ac849a5e16c7ce8580"
       ],
       "layout": "IPY_MODEL_d6e8aa5647ed4d4aadd0a3c49f71bc11"
      }
     },
     "d9075255184343869835ff2d5c74eea5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4409319d49ef4a3fa07c6663e0e9e5c5",
        "IPY_MODEL_069fd1fdbf8f40da9dcdf00b394b63bc"
       ],
       "layout": "IPY_MODEL_8517e0f6324247b7bdcc1cf8ab7f2ee3"
      }
     },
     "dc90d2523c76410ea760fd545412c75f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_bd3362181bf1444fa53c7d0eb93bb695",
       "max": 4,
       "style": "IPY_MODEL_a34ba2ea2a6d4516adfac42d9e8d2458",
       "value": 4
      }
     },
     "dd296ff948814848b9258f5413b6b184": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_91793fc6d43e432498d1bb58a8a83acd",
       "style": "IPY_MODEL_0b554088ad2349c18f664dbf1590cf54",
       "value": "100% 4/4 [00:00&lt;00:00, 13.44it/s]"
      }
     },
     "e0163c429f45473384549678591e0fa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e431e7010dd241b7b3aa85b60b271386": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e52eb4cc1c0b417ebc266ee46eb9e1cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e8bd21d868a74162b12bd615434ca568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5942d978f3f7476784a8cae98d7a1359",
       "max": 4,
       "style": "IPY_MODEL_f63a44b01fed46c3b74ade582f2773f4",
       "value": 4
      }
     },
     "f0ec0397132c4f708cc28fa900b7efbc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f1eb770ddeae4cf8a8fb6ea3ba758e35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fd8158a6ce274b0d816e49252036b12c",
       "style": "IPY_MODEL_9370b3ef4f34454da60d8ee136a57448",
       "value": "100% 4/4 [00:00&lt;00:00, 22.11it/s]"
      }
     },
     "f63a44b01fed46c3b74ade582f2773f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f753bdbf644245338f43cdfa4a69e4bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa3d2eb8611247949058e2e085827e9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fd8158a6ce274b0d816e49252036b12c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
